{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "796a5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75ba7736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# creating a pdf reader object\n",
    "reader = PdfReader('Test.pdf')\n",
    "\n",
    "# printing number of pages in pdf file\n",
    "print(len(reader.pages))\n",
    "\n",
    "# creating a page object\n",
    "\n",
    "\n",
    "# extracting text from page\n",
    "#print(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f721a564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN-LSTM Hybrid Deep Learning Model for Remaining \n",
      "Useful Life Estimation \n",
      "1Muthukumar G, 2Jyosna Philip \n",
      "1 Technical Officer C, Indira Gandhi Centre for Atomic Research (IGCAR), Kalpakkam, Tamilnadu \n",
      "Email: muthuganeshece@gmail.com / muthukumarg@igcar.gov.in \n",
      "2 Student, M.Sc. (Data Science), Christ (deemed to be) University, Pune, India. \n",
      "Email: philipjyosna02@gmail.com \n",
      "1. Introduction \n",
      "Remaining Useful Life (RUL) of a component or a system is defined as the length from the \n",
      "current time to the end of the useful life [2]. Accurate RUL estimation plays a crucial role in \n",
      "Predictive Maintenance applications. If we can accurately predict when an engine will fail, then we \n",
      "can make informed maintenance decision in advance to avoid disasters, reduce the maintenance cost, \n",
      "as well as streamline operational activities, aligning with the principles of industry 4.0 [1, 10]. In \n",
      "general, two types of methodologies are used for RUL estimation: model-based approaches and data-\n",
      "driven approaches. Model-based methodologies build physical failure models for degradation, such as \n",
      "crack, wear, corrosion, etc [1]. Physical models are very useful to solve RUL problem in use-cases \n",
      "where there is no enough failure data available. In such cases, we can induce failures within physical \n",
      "models, augment the actual data with physical model failure data and learn models for RUL \n",
      "estimation. However, such physical failure models are very complex and difficult to build, and \n",
      "physical models for many components do not exist. On the other hand, data-driven methods that \n",
      "employ sensor and operational status data to estimate RUL are more advantageous and economical for \n",
      "equipment with a sufficient number of failures.  \n",
      "In this paper, we conducted a thorough analysis of the data driven approach for RUL estimation. \n",
      "Traditional data driven approach utilizes both linear and non-linear regression techniques to estimate \n",
      "RUL, however they have difficulty achieving high accuracy in this field. Although Multilayer \n",
      "Perceptron (MLP) has been applied to predict RUL, it cannot learn salient features automatically, \n",
      "because of its network structure. However, it is extremely challenging, if not impossible, to accurately \n",
      "predict RUL without a good feature representation method. It is thus highly desirable to develop a \n",
      "systematic feature representation approach to effectively characterize the nature of signals related to \n",
      "the prognostic tasks.  \n",
      "Recently deep learning models are highly popular due to its ability to learn automatically the \n",
      "hierarchical feature representation from raw data. The deep learning architecture contains sequence of \n",
      "layers, each of which applies a non-linear transformation on the outputs of the previous layer. This \n",
      "allows the data to be represented by a hierarchy of features with varying levels of detail. The widely \n",
      "known deep learning models are Convolutional neural network (CNN), Recurrent Neural Network \n",
      "(RNN), Auto-encoders and Transformers.  \n",
      "Convolutional neural network  adapted from deep learning architecture uses different processing \n",
      "units such as convolution, pooling, activation etc., to effectively capture local features from the global \n",
      "data [27]. The deep architecture allows multiple layers of these units to be stacked, enabling the model \n",
      "to identify signal characteristics at different scales . Therefore, the features extracted by CNN are task \n",
      "dependent and non-handcrafted. Moreover, these features offer more predictive power, as the CNN is \n",
      "trained under the supervision of target values. \n",
      "Recurrent Neural Network, a class of deep learning architectures is well suited for modelling time \n",
      "sequence data [25]. However, RNN is known to suffer from long-term temporal dependency problem, \n",
      "as the gradients propagated over multiple stages tend to either vanish or explode. Long Short -Term \n",
      "Memory Network (LSTM) is a form of RNN network for sequence learning tasks  [5, 21] and has \n",
      "achieved remarkable success on speech recognition and machine translation. LSTM addresses the long-\n",
      "term time dependency problem of RNN by controlling information flow using input gate, forget gate \n",
      "and output gate. Long term memory retention is essentially their default mode of operation [23].  \n",
      "While Convolutional Neural Networks  have shown improved accuracy, th ey often overlook the \n",
      "sequential nature of the data, relying instead on features derived from sliding windows. Since RUL \n",
      "prediction inherently involves multivariate time series analysis, robust sequence learning is essential. \n",
      "Therefore, a novel hybrid architecture combining CNN with LSTM networks for RUL estimation \n",
      "is developed in this paper. Although CNN -based LSTM models have been applied to sequence \n",
      "prediction tasks in financial forecasting, this is the first attempt to adopt this approach for RUL \n",
      "estimation in prognostics.  In the proposed architecture for RUL estimation, one dimensional \n",
      "convolutional filters in the initial layer are applied to all the sensor data at each time stamp followed by \n",
      "LSTM layers applied temporally over the time series and the final neural network regression layer \n",
      "employs squared error loss function. In this approach, the CNN layer efficiently extracts features from \n",
      "the data, followed by LSTM  layer, which uses these extracted features to predict RUL. This method \n",
      "effectively leverages sensor sequence information, uncovering hidden patterns within the data, even \n",
      "under multiple operating conditions and fault scenarios. \n",
      "Data-driven approaches involve several key steps, including data collection, data wrangling, \n",
      "exploratory data analysis, feature engineering, and subsequent model preparation and evaluation. In the \n",
      "experiments, the proposed CNN with LSTM based approach for RUL estimation is compared with \n",
      "existing regression-based approaches in the CMAPSS public data set. The results clearly demonstrates \n",
      "that the proposed approach accurately predicts RUL than existing approaches significantly.  \n",
      "The following sections of this article are organized as follows:  Section 2 explains the background \n",
      "and related work.  Section 3  outlines the CNN LSTM hybrid Deep learning architecture . Section \n",
      "4 describes the methodology, and  Section 5  discusses the experimental results.  Finally, Section \n",
      "6 addresses the future work and conclusions. \n",
      "2. Related Work \n",
      "In t his section we primarily focus on regression-based machine learning approaches for RUL \n",
      "estimation. There exist two main categories of ma chine learning -based techniques, t he first one is \n",
      "supervised approaches where the failure information exists in the dataset and t he second one is \n",
      "unsupervised approaches, where there is only process information, and no failure -related information \n",
      "exists [30]. Supervised machine learning methods have been increasingly applied for RUL estimation \n",
      "in the various areas such as medical devices [ 12], automated teller machines (ATM) [ 13], electric \n",
      "propulsion systems [14, 29], rolling-element bearings [ 15], computer workstations [ 16], automobiles \n",
      "[28] and industrial machines [29].  \n",
      "The existing algorithms in the literature for RU L estimation are either based on multivariate time \n",
      "series analysis or damage progression analysis [3, 18, 19, 20, 26]. Many approaches utilize conventional \n",
      "machine learning models such as support vector machines (SVM) [17] and decision tree-based models \n",
      "[12, 13]. An important benefit of these models is their interpretability, as they help identify key factors \n",
      "contributing to machine breakdowns. \n",
      "In [4], a deep convolutional neural network model is used to estimate RUL . In the proposed \n",
      "architecture, convolution filters in the initial layer are two dimensional which is  applied along the \n",
      "temporal dimension over the multi -channel sensor data and final neural network regression layer \n",
      "employs squared error loss function to incorporate automated feature learning from raw sensor signals \n",
      "in a systematic way.  Li et al. [ 32] developed a multi -scale deep convolutional neural network (MS -\n",
      "DCNN) and used the min-max normalization with the MS-DCNN algorithm for RUL prediction. They \n",
      "compared the performance of their model with other state -of-the-art models and showed that the new \n",
      "model provides promising results on the NASA C-MAPSS dataset [26]. \n",
      "In [ 5], LSTM network model is utilise d for the accurate  RUL estimation . Due to the inherent \n",
      "sequential nature of sensor data, LSTM is well suited for RUL estimation. In this approach, multiple \n",
      "layers of LSTM cells in combination with feed forward layers to uncover hidden patterns in sensor data \n",
      "at various stages of degradation. \n",
      "A set of turbo engine run-to-failure datasets is provided by NASA [26, 31], and the data is used in \n",
      "many research papers to predict the RUL. Ramasso and Saxena [24] published a survey on prognostic \n",
      "methods used for the NASA turbo engine datasets and divided the prognostic approaches  into three \n",
      "categories. The first category is the use of functional mappings between the set of inputs and RUL. For \n",
      "the first category, they reported that the dominant underlying machine learning algorithm is artificial \n",
      "neural networks (ANNs) [22]. The second category of techniques is the functional mapping between \n",
      "the health index and RUL. The third category is similarity -based matching techniques. Benchmarking \n",
      "of prognostic methods has been conducted on the NASA turbo engine dataset, and it was shown that  \n",
      "most of the studies use a health index to map between input features and the RUL. \n",
      "In several studies, indirect measurements of RUL are used in place of direct observations. Because \n",
      "of this, estimating the RUL frequently involves the use of the health inde x (HI) concept [34]. Rather \n",
      "than directly predicting the RUL, a machine learning model is trained to forecast the HI of a turbo \n",
      "engine for each cycle . Ziqiu et al. [33] used the notion of  HI and the Multilayer Perceptron (MLP) \n",
      "machine learning method in combination with feature normalization, Principal Component Analysis \n",
      "(PCA), and feature selection approaches  to estimate the RUL . They also used the NASA CMAPSS \n",
      "dataset to assess the performance of their model. \n",
      "In our study, we adopt to the supervised machine learning approach for the estimation of RUL using \n",
      "a deep CNN combined with LSTM architecture. In consistent with other models, we thoroughly \n",
      "investigate the effectiveness of this innovative model and compare its performance against other \n",
      "established machine learning algorithms using the NASA turbo engine datasets. \n",
      "3. CNN LSTM Hybrid Deep Learning Architecture for RUL Estimation \n",
      "This section presents the proposed architecture of CNN LSTM hybrid deep learning model for RUL \n",
      "estimation. CNN have great potential to identify the various salient patterns of sensor signals. However, \n",
      "in RUL estimation we confront with multiple  channels of time series signals, in which the traditional \n",
      "CNN cannot be used directly. Hence, we hybrid the LSTM network to capture temporal dimension. The \n",
      "LSTM module receives the output from the CNN module and processes it sequentially to capture long-\n",
      "term dependencies and temporal patterns . It uses multiple layers of LSTM cells in combination with \n",
      "standard feed forward layers to discover hidden patterns from sensor data. The overview block diagram \n",
      "of the CNN LSTM architecture is shown in the Fig. 1. \n",
      " \n",
      " \n",
      " \n",
      "Fig. 1: Block Diagram of proposed CNN LSTM hybrid architecture \n",
      "3.1.  Convolutional Neural Network  \n",
      "In our work, we have limited the architecture to a single CNN layer, which consists of one \n",
      "convolution layer followed by a pooling layer. This simplified structure is sufficient for this task, which \n",
      "helps to reduce computational complexity. In the convolution layer, the input sensor data at a specific \n",
      "time instant is processed using one -dimensional convolutional kernels. We apply 64 one dimensional \n",
      "convolution filters  and relu activation function . In the pooling layer, we use one dimensional max \n",
      "pooling without overlapping, where the input feature maps are divided into non -overlapping regions, \n",
      "and for each sub-region, the maximum value is taken as the output. \n",
      "3.2.  LSTM Model \n",
      "LSTM cell uses memory cells and three gates as shown in Fig. 2.  \n",
      " \n",
      "Fig. 2: LSTM Cell \n",
      "The forget gate determines what information to discard, the input gate controls new information \n",
      "added, and the output gate manages how much of the cell state is used for output  as shown in Fig. 2 .  \n",
      "Sensor \n",
      "Inputs \n",
      "CNN \n",
      "Layer \n",
      "Pooling \n",
      "Layer \n",
      "LSTM \n",
      "Layer \n",
      "Dense \n",
      "Layer \n",
      "RUL \n",
      "Output \n",
      "This structure allows LSTMs to effectively retain important informati on over time, making them \n",
      "suitable for tasks like time -series prediction and sequence modeling.  Hence, we split the dataset into \n",
      "multiple fixed length time series data of length 30 and applied to the model.  \n",
      "3.3.  CNN LSTM Architecture \n",
      "The CNN module processes the input data and extracts relevant spatial features through \n",
      "convolutional layers. These layers employ filters to capture local patterns within the input sequences, \n",
      "enabling the model to learn hierarchical representations of the data. The LSTM module rece ives the \n",
      "output from the CNN module and processes it sequentially to capture long -term dependencies and \n",
      "temporal patterns. In the proposed CNN LSTM hybrid architecture shown in Fig. 3, leverages the \n",
      "strengths of both CNNs and LSTMs to capture spatial patterns and long-term dependencies in sequential \n",
      "data. We combined the 1D convolution layer followed by pooling layer with multiple LSTM and fully \n",
      "connected layers. CNN takes the input sensor data at each time step and its output is passed to LSTM \n",
      "layer. The LSTM output is then fed into fully connected layers, and the final regression layer predicts \n",
      "the RUL. \n",
      " \n",
      "Fig. 3: CNN LSTM Hybrid Architecture Model  \n",
      "3.4.  Model Evaluation \n",
      "In order to evaluate the performance of a RUL estimation model on the test data, Root Mean \n",
      "Square Error (RMSE) Eq. (1), gives equal penalty weights to the model when the estimated RUL is \n",
      "smaller than true RUL and when the estimated RUL is larger than true RUL.  \n",
      " \n",
      "              (1) \n",
      " \n",
      "Eq. (2) is R² Score, which is also widely used as an evaluation metric for the estimation of RUL. It \n",
      "represents the proportion of variance in the target variable that can be explained by the independent \n",
      "variables in the model. Mathematically, the R² score is defined as: \n",
      " \n",
      "           (2) \n",
      "  \n",
      "Where SSres is the sum of squared residuals (the differences between the observed and predicted \n",
      "values), and SStot is the total sum of squares (the differences between the observed values and their \n",
      "mean). R² score of 1 indicates that the model perfectly explains all the variability in the target variable \n",
      "and an R² score of 0 suggests that the model fails to explain any variability and performs no better \n",
      "than a simple mean-based prediction. \n",
      "In literature, scoring function is given to measure the quality of the models [4, 5]. Eq. (3) shows \n",
      "the definition of scoring function. \n",
      " \n",
      "               (3) \n",
      "\n",
      "Where n is total number of samples in the test set, hi = RULest,i - RULi, RULi is true RUL for the \n",
      "test sample ‘i’. Eq. (3) gives different penalty when the model underestimates RUL and when the \n",
      "model overestimates RUL. If estimated RUL is less than the true RUL, the penalty is smaller, because \n",
      "there is still time to conduct maintenance and it will not cause significant system failure. If estimated \n",
      "RUL is larger than true RUL, the penalty is larger, because under such estimation, the maintenance \n",
      "will be scheduled later than the required time and it may cause system failure. \n",
      "4. Methodology \n",
      "This section outlines the key steps taken before the modeling phase. It starts with preparing features \n",
      "and target variables, followed by data analysis to explore relationships between variables using \n",
      "visualizations. Data pre -processing is then discussed, including filtering and normalization. Feature \n",
      "engineering is applied to create or modify features for better predictive power. Finally, techniques like \n",
      "Principal Component Analysis (PCA) and feature selection are used to remove redundant or irrelevant \n",
      "features. \n",
      "4.1. Data Preparation \n",
      "The dataset comprises multiple multivariate time series sensor data, which is divided into training \n",
      "and test subsets. Each time series is from a different engine i.e., the data can be considered to be from \n",
      "a fleet of engines of the same type. Every engine has varying degrees of initial wear and manufacturing \n",
      "variance in the beginnin g. This variation and wear are regarded as normal and do not indicate a \n",
      "malfunction. The data is contaminated with sensor noise. The engine is operating normally at the start \n",
      "of each time series, and develops a fault at some point during the series. In the  training set, the fault \n",
      "grows in magnitude until system failure. In the test set, the time series ends some time prior to syste m \n",
      "failure. The objective is to predict the number of remaining operational cycles before failure in the test \n",
      "set, or in other words the number of cycles the engine will continue to operate after the last recorded \n",
      "cycle. In addition to that a vector of true RUL for the test set is also provided in the dataset. \n",
      "The dataset contains 26 numerical features, where each row represents a snapshot of data collected \n",
      "in a single operational cycle across 100 different engines. Sensor data is recorded during each engine \n",
      "power cycle and is gathered for one hundred distinct engines. Engine ID, Time in Cycles, Settings 1, 2, \n",
      "3, and the remaining columns all contain sensor data. There is no formal definition of the specifics of \n",
      "any sensor data. \n",
      " \n",
      "Fig. 4: Piece-wise RUL of the Data Set (Piece-wise maximum RUL is 130-time cycles) \n",
      "The target variable is not exp licitly provided in the dataset,  instead it is calculated by subtracting \n",
      "the number of cycles from the engine’s maximum cycle. This leads to a new column labelled \n",
      "\"Remaining Cycles,\" which becomes the target variable and it represents the Remaining Useful Life of \n",
      "the engine. The health of a system generally degrades linearly along with time. In practical applications, \n",
      "a component's degradation is minimal at first and grows as it gets closer to its end of life. A piece-wise \n",
      "linear RUL target function was proposed in [3, 4] , in order to better reflect the changes in Remaining \n",
      "Useful Life over time. This function sets a maximum RUL and then begins linear degradation at a \n",
      "specific usage level as shown in the Fig. 4. We set the maximum limit as 130 time cycles for all the \n",
      "engines. \n",
      "\n",
      "4.2. Data Analysis \n",
      "The Fig. 5 shows the sensor readings for one of the engines over the course of its lifetime. The \n",
      "sensor values are displayed on the Y-axis, while the power cycles are represented on the X-axis. From \n",
      "the graph, it can be observed that sensors such as Sensor 3, Sensor 4, Sensor 8, Sensor 9, Sensor 13, \n",
      "Sensor 19, Sensor 21, and Sensor 22 maintain constant readings throughout their lifecycle. Since these \n",
      "constant sensor readings do not contribute any predictive value, these features can be safely removed \n",
      "from the dataset. \n",
      " \n",
      " \n",
      "Fig 5: Time series sensor data of one of the Engines \n",
      "The distribution of each sensor data in the dataset varies significantly. As per Fig. 6, some \n",
      "sensors, such as 1, 5, and 6, exhibit a normal distribution  and the remaining sensors display skewed \n",
      "distributions, either to the right or left. This diverse range of data distributions necessitates tailored pre-\n",
      "processing techniques to ensure optimal model performance. \n",
      " \n",
      "\n",
      " \n",
      "Fig. 6: Frequency Distribution Plot for Sensor Data \n",
      " \n",
      "Fig. 7: Parallel Coordinates plot for CMAPSS Dataset \n",
      "Parallel Plot [11] is a type of data visualization used to explore and analyse multi-dimensional \n",
      "data. Parallel pl ot applied to the dataset  is displayed in Fig. 7,  where dark blue lines represent \n",
      "observations with more remaining cycles, while yellow lines indicate lower remaining cycles.  The \n",
      "sensor values tend to be more consistent and grouped together in the early cycles, which are represented \n",
      "by dark blue lines and suggest stable operation. Sensor readings begin to differ as the engines get closer \n",
      "to the middle of their lives; this is a sign of both performance discrepancies and the onset of defects. \n",
      "The sensor values exhibit a substantial divergence, suggesting wear and degradation, as the sensor \n",
      "approaches its end of life, indicated by yellow lines.  \n",
      "The sensor data for all engines is illustrated in the Fig. 8. The green dots in this graphic show \n",
      "the exponential moving average of the sensor data for one engine throughout the course of its lifetime, \n",
      "while the red points show the points at which each engine fails. With the exception of Sensors 1 and 2, \n",
      "it is clear from the figure that the majority of sensors are able to differentiate between the engine's \n",
      "\n",
      "normal operating circumstances and failure scenarios. As a result, the characteristics associated with \n",
      "Sensors 1 and 2 can be disregarded for additional examination. Furthermore, some sensor readings are \n",
      "positive correlation with degradation and while others show a negatively correlation.  \n",
      " \n",
      " \n",
      "Fig. 8: Scatter plot representation of sensor data of all engines \n",
      "4.3.  Data Pre-processing \n",
      "Data preprocessing is essential before modeling as it enhances data quality, ensuring that the \n",
      "input data is accurate, consistent, and relevant.  The techniques such as cleaning and standardization \n",
      "rectify errors and inconsistencies, leading to more reliable models.  \n",
      "4.3.1. Data Filtering \n",
      "The sensor data in the dataset are noisy and sporadic, necessitating the application of \n",
      "smoothing filters to improve data quality. Two widely used smoothing techniques such as Simple \n",
      "Moving Average (SMA) and Exponential Moving Average (EMA), were applied with various \n",
      "weights to determine the most effective method. Upon evaluation, EMA with an alpha value of 0.1 \n",
      "visually outperformed other configurations. Consequently, EMA with this alpha value was selected \n",
      "and applied to the sensor data, resulting in a smoother and more reliable data. Fig. 9 shows a visual \n",
      "comparison of raw sensor data and the exponential mean of sensor data with alpha = 0.1. In the raw \n",
      "data, the data points are far more scattered than their corresponding exponential mean. Therefore, the \n",
      "modified data may provide better results for the model than using the raw sensor data directly. \n",
      "\n",
      " \n",
      "Fig. 9: Comparison between Raw sensor data and exponential moving averaged sensor data \n",
      "4.3.2. Data Standardization \n",
      "Since the value range is substantially different in different variables, it can be difficult to find \n",
      "the optimal point for the cost function. Therefore, the training and testing datasets need to be \n",
      "normalized. There are two widely used methods for normaliz ation, which are Z-scores as specified in \n",
      "Eq. (4) and min-max-scale as specified in Eq. (5). Both methods are applied, and the one with the best \n",
      "evaluation result is selected.  \n",
      "        (4) \n",
      " \n",
      " \n",
      "         (5) \n",
      " \n",
      "4.4.  Feature Engineering \n",
      "In the dataset, some features exhibit constant values throughout all observations, resulting in \n",
      "zero variance. These features are removed in the previously discussed data analysis section, as they \n",
      "provide no meaningful insight into the relationship between the input variables and the target variable. \n",
      "In addition to that, feature transformation can be applied to further optimize the dataset. By removing \n",
      "or transforming such features, the model's performance can be significantly improved. \n",
      "4.4.1. Principal Component Analysis \n",
      "As part of feature engineering, Principal Component Analysis (PCA) was applied to reduce the \n",
      "dimensionality of the high -dimensional sensor data. PCA projects the data onto orthogonal axes, \n",
      "retaining the most significant features. The cum ulative explained variance ratio, shown in Fig. 10, \n",
      "indicates that the first two components capture around 70% of the variance, while 12 components \n",
      "account for nearly 99%. Therefore, the data dimension can be reduced from 24 to 12 with minimal loss \n",
      "of information. \n",
      " \n",
      "Fig. 10: Explained Variance Ratio of Principal Components \n",
      "The first, second, and third principal components are studied extensively as they represent 75% \n",
      "of the dataset's variance. Fig. 11 represents the scatter plot for the complete dataset, wh ere green dots \n",
      "represent the starting points of the engine cycles, and orange dots represent the failure points. It becomes \n",
      "evident from the scatter plot that thresholding the first principal component can effectively determine \n",
      "the failure point of all engines, irrespective of the other principal components. \n",
      "\n",
      " \n",
      "Fig. 11: Correlation plot of first 3 principal components \n",
      "4.4.2. Multi collinearity Analysis \n",
      "When working with multiple numerical features in a dataset, it is essential to analyse the \n",
      "correlation between these features. Highly correlated features can introduce redundancy, biasing the \n",
      "model and ultimately reducing the accuracy of predictions. When two or more features provide similar \n",
      "information, the model may overemphasize their contributions, leading to overfitting or skewed results. \n",
      "From the heat map shown in Fig. 12, it is evident that lot of features are highly correlated and it can \n",
      "lead to multi collinearity problem. Multicollinearity refers to the situation where two or more f eatures \n",
      "in a dataset are highly correlated, which can negatively impact the performance of machine learning \n",
      "models. Therefore, it is crucial to select features that contribute the most to the model's performance \n",
      "while minimizing redundancy. \n",
      " \n",
      "Fig. 12: Heat map of the features in CMAPSS dataset \n",
      "4.4.3. Feature Selection \n",
      "From the Fig. 13, it is evident that the first principal component can be segregated to indicate \n",
      "failure, which helps the model in tuning the remaining useful life (RUL). Therefore, the first principal \n",
      "component is included as an additional feature for model development. This inclusion enhances the \n",
      "model's ability to predict RUL more accurately by leveraging the significant variance captured by the \n",
      "first principal component. \n",
      " \n",
      "Fig. 13: Principal Components Vs Cycles \n",
      "\n",
      "To tackle the issue of multicollinearity , as discussed in the previous section , we applied the \n",
      "Select K Best algorithm. This algorithm ranks all the features according to a specified statistical \n",
      "criterion and selects the top K features that are most significant for predicting the target variable. Fig. \n",
      "14 clearly shows that the logarithmic F-scores of Sensor1 and Sensor2 are significantly low, indicating \n",
      "their minimal importance. Therefore, these sensors can be removed due to their limited contribution. \n",
      " \n",
      "Fig. 14: Features ranked based on F-scores by Select K Best Algorithm \n",
      "5. Experiments and Results \n",
      "In this section, we have performed extensive experiments for comparison of the proposed CNN \n",
      "LSTM based deep learning model with traditional regression algorithms such as Linear Regression, \n",
      "Random Forest  [6], and state -of-the-art algorithms, including Multi -layer Perceptron (MLP)  [9], \n",
      "XGBoost [7, 8] and LSTM on the CMAPSS data set. The hyper  parameters of all the techniques, are \n",
      "chosen using standard 5 -fold cross -validation procedure, where we tune their parameter values for \n",
      "training these models and choose their final values that give the best results. \n",
      "The hyperparameter tuning for the Random Forest, XG boost, MLP are performed as shown in the \n",
      "Table 1 and Table 2.  \n",
      "Table 1: Hyperparameter Tuning for Random Forest \n",
      "Hyperparameter Description List of Values Best Estimator \n",
      "n_estimators No. of Trees [100,200,300] 300 \n",
      "max_depth Maximum depth of trees [6,8,10,12,14] 6 \n",
      "min_samples_leaf Minimum of samples for leaf [4,6,8,10] 4 \n",
      "ccp_alpha Tree pruning factor [0,1,2] 0 \n",
      "Table 2: Hyperparameter Tuning for XG Boost \n",
      "Hyperparameter Description List of Values Best Estimator \n",
      "learning_rate Learning Rate [0.05,0.1,0.2] 0.1 \n",
      "n_estimators No. of Trees [70,100,200,300] 70 \n",
      "max_depth Maximum depth of trees [3,4,5] 3 \n",
      "min_child_weight Minimum sum of instance weights [70,100,150,200] 200 \n",
      "Table 3: Hyperparameter Tuning for MLP \n",
      "Hyperparameter Description List of Values Best Estimator \n",
      "learning_rate Learning Rate [0.05,0.1,0.2] 0.1 \n",
      "n_layers No. of layers [3,4,5,6] 5 \n",
      "layer_sizes No. of neuron in layers \n",
      "[8.16.64.32.8, \n",
      "16.32.64.32.16, \n",
      "32.64.64.32.16] \n",
      "32.64.64.32.16 \n",
      "\n",
      "The performance of the previously discussed machine learning algorithms are compared with the \n",
      "performance of the proposed model and the results are shown in Table 4. From the table, it is evident \n",
      "that the proposed hybrid CNN-LSTM model demonstrates the better RMSE and offering a superior R² \n",
      "score compared to the other methods. \n",
      "Table 4: Performance comparison on C-MAPSS dataset \n",
      "Model RMSE R2 \n",
      "Linear Regression 43.18 0.46 \n",
      "Random Forest 6.68 0.42 \n",
      "XG Boost 17.35 0.65 \n",
      "MLP 4.51 0.52 \n",
      "LSTM 15.93 0.75 \n",
      "CNN LSTM 13.34 0.86 \n",
      " \n",
      "6. Conclusion and Future work \n",
      "We proposed CNN LSTM based deep learning approach for RUL estimation and we showed its \n",
      "benefits by taking sequence information when estimating RUL. Our experiments on C-MAPSS dataset \n",
      "showed that our proposed model outperforms other approaches and gives the best performance in RUL \n",
      "estimation. In addition to that, the work involves the entire lifecycle of predictive maintenance, starting \n",
      "with data collection, followed by comprehensive data preparation and pre -processing stages to ensure \n",
      "data quality and consistency. Feature scaling, Pr incipal Component Analysis (PCA), and feature \n",
      "selection techniques were applied to refine the dataset and identify the most relevant features for \n",
      "modeling. Multiple algorithms, including Linear Regression, Random Forest, XG-Boost, MLP, and \n",
      "LSTM, were developed and evaluated using RMSE and R² metrics. Future work will focus on extending \n",
      "this experiment to other RUL estimation datasets to validate the robustness of the proposed model across \n",
      "different scenarios. A notable challenge with the proposed model is its computational complexity, \n",
      "which impacts its suitability for deployment in embedded devices. To address this, optimization \n",
      "strategies will be explored to increase the model's computation speed, making it more efficient and \n",
      "feasible for real-time applications on low-power embedded systems.  \n",
      "7. Acknowledgements \n",
      "The authors would like to express their gratitude and appreciation to their team members,  Abhay \n",
      "Sharma, Anchal Sekhri, Sana Zehra and Khunwana Zeno, for their invaluable inputs and support during \n",
      "the course of a project related to this research work. \n",
      "8. References \n",
      "[1] S. Duffuaa, M. Ben-Daya, K. Al-Sultan, and A. Andijani: “A generic conceptual simulation model \n",
      "for maintenance systems,” Journal of Quality in Maintenance Engineering, vol. 7, pp. 207–219, 2001. \n",
      "[2] X.-S. Si, W. Wang, C.-H. Hu, and D.-H. Zhou: “Remaining useful life estimation–a review on the \n",
      "statistical data driven approaches,” European Journal of Operational Research, vol. 213, pp. 1–14, 2011 \n",
      "[3] Heimes, F.O.: “Recurrent neural networks for remaining useful life estimation ”, in International \n",
      "Conference on Prognostics and Health Management, 2008.  \n",
      "[4] G. S. Babu, P. Zhao, and X.-L. Li: “Deep convolutional neural network based regression approach \n",
      "for estimation of remaining useful life,” in International Conference on Database Systems for Advanced \n",
      "Applications. Springer, 2016, pp. 214–228 \n",
      "[5] Shuai Zheng, Kosta Ristovski, Ahmed Farahat and Chetan Gupta : “Long Short -Term Memory \n",
      "Network for Remaining Useful Life Estimation,” in IEEE ICPHM, 2017 \n",
      "[6] Breiman. L: “Random Forests”, Machine Learning, 45(1), 5-32, 2001 \n",
      "[7] Chen. T & Guestrin. C: “XGBoost: A Scalable Tree Boosting System”, in Proceedings of the 22nd \n",
      "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016. \n",
      "[8] Xgboost Developers: “XGBoost Documentation”, Available: https://xgboost.readthedocs.io \n",
      "[9] Scikit-learn Developers: “Scikit-learn Documentation: MLPRegressor”, Available: https://scikit-\n",
      "learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html \n",
      "[10] S. Abirami and P. Chitra : “The Digital Twin Paradigm for Smarter Systems and Environments: \n",
      "The Industry Use Cases,” in Advances in Computers, 2020. \n",
      "[11] Wegman, E. J. : “Hyperdimensional Data Analysis Using Parallel Coordinates, ” Journal of the \n",
      "American Statistical Association, vol. 85, 1990 \n",
      "[12] Ruben Sipos, Dmitriy Fradkin, Fabian Moerchen, and Zhuang Wang : “Log based predictive \n",
      "maintenance”, in Proceedings of the 20th ACM SIGKDD international conference on knowledge \n",
      "discovery and data mining. 1867–1876. \n",
      "[13] Antoine Guillaume, Christel Vrain, and Elloumi Wael : “Time series classification for predictive \n",
      "maintenance on event logs”, arXiv: 2011.10996, 2020. \n",
      "[14] Deokwoo Jung, Zhenjie Zhang, and Marianne Winslett : “Vibration analysi s for IOT enabled \n",
      "predictive maintenance”, in IEEE 33rd International Conference on Data Engineering (ICDE), 2017.  \n",
      "[15] Dovile Juodelyte, Veronika Cheplygina, Therese Graversen, and Philippe Bonnet : “Predicting \n",
      "Bearings Degradation Stages for Predictive Maintenance in the Pharmaceutical Industry”, 2022. \n",
      "[16] Alexander Nikitin and Samuel Kaski:  “Human-in-the-Loop Large-Scale Predictive Maintenance \n",
      "of Workstations”, in Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and \n",
      "Data Mining, 2022. \n",
      "[17] Corinna Cortes and Vladimir Vapnik: “Support-vector networks”, Machine learning, 1995. \n",
      "[18] Wang, T., Yu, J., Siegel, D., Lee, J.: “A similarity-based prognostics approach for remaining \n",
      "useful life estimation of engineered systems”, in International Conference on Prognostics and Health \n",
      "Management, 2008. \n",
      "[19] Lim, P., Goh, C.K., Tan, K.C., Dutta, P.: “Estimation of remaining useful life based on switching \n",
      "kalman filter neural network ensemble”, in Annual Conference of the prognostics and Health \n",
      "Management Society, 2014, pp. 1–8 \n",
      "[20] Ramasso, E., Saxena, A.: “Review and analysis of algorithmic approaches developed for \n",
      "prognostics on CMAPSS dataset”, in Annual Conference of the Prognostics and Health Management \n",
      "Society, 2014, pp. 1–11 \n",
      "[21] F. A. Gers, D. Eck, and J. Schmidhuber: “Applying LSTM to time series predictable through \n",
      "time-window approaches,” pp. 669–676, 2001. \n",
      "[22] Z. Tian: “An artificial neural network method for remaining useful life prediction of equipment \n",
      "subject to condition monitoring,” Journal of Intelligent Manufacturing, vol. 23, pp. 227–237, 2012. \n",
      "[23] S. Hochreiter and J. Schmidhuber: “Long short-term memory,” Neural computation, vol. 9, no. 8, \n",
      "pp. 1735–1780, 1997. \n",
      "[24] E. Ramasso and A. Saxena: “Performance benchmarking and analysis of prognostic methods for \n",
      "cmapss datasets.” International Journal of Prognostics and Health Management, vol. 5, pp. 1–15, 2014 \n",
      "[25] Connor, J.T., Martin, R.D., Atlas, L.E.: “Recurrent neural networks and robust time series \n",
      "prediction”, IEEE Transactions on Neural Networks 5(2), 240–254, 1994 \n",
      "[26] Saxena, A., Goebel, K., Simon, D., Eklund, N: “Damage propagation modeling for aircraft \n",
      "engine run-to-failure simulation”, in International Conference on Prognostics and Health \n",
      "Management, 2008. PHM 2008. pp. 1–9 \n",
      "[27] Yang, J.B., Nguyen, M.N., San, P.P., Li, X.L., Krishnaswamy, S: “Deep convolutional neural \n",
      "networks on multichannel time series for human activity recognition”, in Proceedings of the 24th \n",
      "International Conference on Artificial Intelligence. pp. 3995–4001. AAAI Press (2015) \n",
      "[28] Abdul Basit Hafeez, Eduardo Alonso, Aram Ter-Sarkisov: “Towards Sequential Multivariate \n",
      "Fault Prediction for Vehicular Predictive Maintenance”, in 20th IEEE International Conference on \n",
      "Machine Learning and Applications (ICMLA), 2021 \n",
      "[29] Hadi Ashraf Raja, Karolina Kudelina, Bilal Asad and Toomas Vaimann: “Fault Detection and \n",
      "Predictive Maintenance of Electrical Machines”, IntechOpen: London, UK, 2022 \n",
      "[30] Susto G.A., Schirru A., Pampuri S., McLoone S., Beghi A.: “Machine learning for predictive \n",
      "maintenance: A multiple classifier approach”, in IEEE Trans. Ind. Inform., 2014 \n",
      "[31] Saxena A., Goebel K.: “Turbofan Engine Degradation Simulation Data Set”, 2008 \n",
      "[32] Li H., Zhao W., Zhang Y., Zio E.: “Remaining useful life prediction using multi-scale deep \n",
      "convolutional neural network”, Appl. Soft Computing, 2020 \n",
      "[33] Ziqiu Kang, Cagatay Catal, and Bedir Tekinerdogan: “Remaining Useful Life (RUL) Prediction \n",
      "of Equipment in Production Lines Using Artificial Neural Networks”, PubMed Central, 2021 \n",
      "[34] Riad A., Elminir H., Elattar H.: “Evaluation of neural networks in the subject of prognostics as \n",
      "compared to linear regression model”, in International Journal of Engineering and Technology, 2010 \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "document_text = \"\"\n",
    "for i in range(len(reader.pages)):\n",
    "    document_text = document_text + \"\\n\" + reader.pages[i].extract_text()\n",
    "print(document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "520b73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dfc6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [re.sub(r\"[\\n|\\.]\", \"\", item) for item in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "875b7dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN-LSTM Hybrid Deep Learning Model for Remaining Useful Life Estimation 1Muthukumar G, 2Jyosna Philip 1 Technical Officer C, Indira Gandhi Centre for Atomic Research (IGCAR), Kalpakkam, Tamilnadu Email: muthuganeshece@gmailcom / muthukumarg@igcargovin 2 Student, MSc',\n",
       " '(Data Science), Christ (deemed to be) University, Pune, India',\n",
       " 'Email: philipjyosna02@gmailcom 1',\n",
       " 'Introduction Remaining Useful Life (RUL) of a component or a system is defined as the length from the current time to the end of the useful life [2]',\n",
       " 'Accurate RUL estimation plays a crucial role in Predictive Maintenance applications',\n",
       " 'If we can accurately predict when an engine will fail, then we can make informed maintenance decision in advance to avoid disasters, reduce the maintenance cost, as well as streamline operational activities, aligning with the principles of industry 40 [1, 10]',\n",
       " 'In general, two types of methodologies are used for RUL estimation: model-based approaches and data-driven approaches',\n",
       " 'Model-based methodologies build physical failure models for degradation, such as crack, wear, corrosion, etc [1]',\n",
       " 'Physical models are very useful to solve RUL problem in use-cases where there is no enough failure data available',\n",
       " 'In such cases, we can induce failures within physical models, augment the actual data with physical model failure data and learn models for RUL estimation',\n",
       " 'However, such physical failure models are very complex and difficult to build, and physical models for many components do not exist',\n",
       " 'On the other hand, data-driven methods that employ sensor and operational status data to estimate RUL are more advantageous and economical for equipment with a sufficient number of failures',\n",
       " 'In this paper, we conducted a thorough analysis of the data driven approach for RUL estimation',\n",
       " 'Traditional data driven approach utilizes both linear and non-linear regression techniques to estimate RUL, however they have difficulty achieving high accuracy in this field',\n",
       " 'Although Multilayer Perceptron (MLP) has been applied to predict RUL, it cannot learn salient features automatically, because of its network structure',\n",
       " 'However, it is extremely challenging, if not impossible, to accurately predict RUL without a good feature representation method',\n",
       " 'It is thus highly desirable to develop a systematic feature representation approach to effectively characterize the nature of signals related to the prognostic tasks',\n",
       " 'Recently deep learning models are highly popular due to its ability to learn automatically the hierarchical feature representation from raw data',\n",
       " 'The deep learning architecture contains sequence of layers, each of which applies a non-linear transformation on the outputs of the previous layer',\n",
       " 'This allows the data to be represented by a hierarchy of features with varying levels of detail',\n",
       " 'The widely known deep learning models are Convolutional neural network (CNN), Recurrent Neural Network (RNN), Auto-encoders and Transformers',\n",
       " 'Convolutional neural network  adapted from deep learning architecture uses different processing units such as convolution, pooling, activation etc, to effectively capture local features from the global data [27]',\n",
       " 'The deep architecture allows multiple layers of these units to be stacked, enabling the model to identify signal characteristics at different scales ',\n",
       " 'Therefore, the features extracted by CNN are task dependent and non-handcrafted',\n",
       " 'Moreover, these features offer more predictive power, as the CNN is trained under the supervision of target values',\n",
       " 'Recurrent Neural Network, a class of deep learning architectures is well suited for modelling time sequence data [25]',\n",
       " 'However, RNN is known to suffer from long-term temporal dependency problem, as the gradients propagated over multiple stages tend to either vanish or explode',\n",
       " 'Long Short -Term Memory Network (LSTM) is a form of RNN network for sequence learning tasks  [5, 21] and has achieved remarkable success on speech recognition and machine translation',\n",
       " 'LSTM addresses the long-term time dependency problem of RNN by controlling information flow using input gate, forget gate and output gate',\n",
       " 'Long term memory retention is essentially their default mode of operation [23]',\n",
       " 'While Convolutional Neural Networks  have shown improved accuracy, th ey often overlook the sequential nature of the data, relying instead on features derived from sliding windows',\n",
       " 'Since RUL prediction inherently involves multivariate time series analysis, robust sequence learning is essential']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5122208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"CNN-LSTM Hybrid \\nDeep Learning Model. for Remaining \\nUseful Life Estimation 1Muthukumar G, 2Jyosna Philip 1 Technical Officer C, Indira Gandhi Centre for Atomic Research (IGCAR), Kalpakkam, Tamilnadu Email: muthuganeshece@gmail.com / muthukumarg@igcar.gov.in 2 Student, M.Sc.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9bed089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNN-LSTM Hybrid Deep Learning Model for Remaining Useful Life Estimation 1Muthukumar G, 2Jyosna Philip 1 Technical Officer C, Indira Gandhi Centre for Atomic Research (IGCAR), Kalpakkam, Tamilnadu Email: muthuganeshece@gmailcom / muthukumarg@igcargovin 2 Student, MSc'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"[\\n|\\.]\", \"\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daeeb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "paragraphs = page.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cdba0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN-LSTM Hybrid Deep Learning Model for Remaining ',\n",
       " 'Useful Life Estimation ',\n",
       " '1Muthukumar G, 2Jyosna Philip ',\n",
       " '1 Technical Officer C, Indira Gandhi Centre for Atomic Research (IGCAR), Kalpakkam, Tamilnadu ',\n",
       " 'Email: muthuganeshece@gmail.com / muthukumarg@igcar.gov.in ',\n",
       " '2 Student, M.Sc. (Data Science), Christ (deemed to be) University, Pune, India. ',\n",
       " 'Email: philipjyosna02@gmail.com ',\n",
       " '1. Introduction ',\n",
       " 'Remaining Useful Life (RUL) of a component or a system is defined as the length from the ',\n",
       " 'current time to the end of the useful life [2]. Accurate RUL estimation plays a crucial role in ',\n",
       " 'Predictive Maintenance applications. If we can accurately predict when an engine will fail, then we ',\n",
       " 'can make informed maintenance decision in advance to avoid disasters, reduce the maintenance cost, ',\n",
       " 'as well as streamline operational activities, aligning with the principles of industry 4.0 [1, 10]. In ',\n",
       " 'general, two types of methodologies are used for RUL estimation: model-based approaches and data-',\n",
       " 'driven approaches. Model-based methodologies build physical failure models for degradation, such as ',\n",
       " 'crack, wear, corrosion, etc [1]. Physical models are very useful to solve RUL problem in use-cases ',\n",
       " 'where there is no enough failure data available. In such cases, we can induce failures within physical ',\n",
       " 'models, augment the actual data with physical model failure data and learn models for RUL ',\n",
       " 'estimation. However, such physical failure models are very complex and difficult to build, and ',\n",
       " 'physical models for many components do not exist. On the other hand, data-driven methods that ',\n",
       " 'employ sensor and operational status data to estimate RUL are more advantageous and economical for ',\n",
       " 'equipment with a sufficient number of failures.  ',\n",
       " 'In this paper, we conducted a thorough analysis of the data driven approach for RUL estimation. ',\n",
       " 'Traditional data driven approach utilizes both linear and non-linear regression techniques to estimate ',\n",
       " 'RUL, however they have difficulty achieving high accuracy in this field. Although Multilayer ',\n",
       " 'Perceptron (MLP) has been applied to predict RUL, it cannot learn salient features automatically, ',\n",
       " 'because of its network structure. However, it is extremely challenging, if not impossible, to accurately ',\n",
       " 'predict RUL without a good feature representation method. It is thus highly desirable to develop a ',\n",
       " 'systematic feature representation approach to effectively characterize the nature of signals related to ',\n",
       " 'the prognostic tasks.  ',\n",
       " 'Recently deep learning models are highly popular due to its ability to learn automatically the ',\n",
       " 'hierarchical feature representation from raw data. The deep learning architecture contains sequence of ',\n",
       " 'layers, each of which applies a non-linear transformation on the outputs of the previous layer. This ',\n",
       " 'allows the data to be represented by a hierarchy of features with varying levels of detail. The widely ',\n",
       " 'known deep learning models are Convolutional neural network (CNN), Recurrent Neural Network ',\n",
       " '(RNN), Auto-encoders and Transformers.  ',\n",
       " 'Convolutional neural network  adapted from deep learning architecture uses different processing ',\n",
       " 'units such as convolution, pooling, activation etc., to effectively capture local features from the global ',\n",
       " 'data [27]. The deep architecture allows multiple layers of these units to be stacked, enabling the model ',\n",
       " 'to identify signal characteristics at different scales . Therefore, the features extracted by CNN are task ',\n",
       " 'dependent and non-handcrafted. Moreover, these features offer more predictive power, as the CNN is ',\n",
       " 'trained under the supervision of target values. ',\n",
       " 'Recurrent Neural Network, a class of deep learning architectures is well suited for modelling time ',\n",
       " 'sequence data [25]. However, RNN is known to suffer from long-term temporal dependency problem, ',\n",
       " 'as the gradients propagated over multiple stages tend to either vanish or explode. Long Short -Term ',\n",
       " 'Memory Network (LSTM) is a form of RNN network for sequence learning tasks  [5, 21] and has ',\n",
       " 'achieved remarkable success on speech recognition and machine translation. LSTM addresses the long-',\n",
       " 'term time dependency problem of RNN by controlling information flow using input gate, forget gate ',\n",
       " 'and output gate. Long term memory retention is essentially their default mode of operation [23].  ',\n",
       " 'While Convolutional Neural Networks  have shown improved accuracy, th ey often overlook the ',\n",
       " 'sequential nature of the data, relying instead on features derived from sliding windows. Since RUL ',\n",
       " 'prediction inherently involves multivariate time series analysis, robust sequence learning is essential. ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f3c7d",
   "metadata": {},
   "source": [
    "# PDF to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5c5e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text_to_fp\n",
    "# Import BytesIO class from io module\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8319dd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML content saved to output.html\n"
     ]
    }
   ],
   "source": [
    "# Specify the PDF file you want to convert to HTML\n",
    "pdf_file = 'Test.pdf'\n",
    "\n",
    "# Create an in-memory buffer to store the HTML output\n",
    "output_buffer = BytesIO()\n",
    "\n",
    "# Convert the PDF to HTML and write the HTML to the buffer\n",
    "with open(pdf_file, 'rb') as pdf_file:\n",
    "    extract_text_to_fp(pdf_file, output_buffer, output_type='html')\n",
    "\n",
    "# Retrieve the HTML content from the buffer\n",
    "html_content = output_buffer.getvalue().decode('utf-8')\n",
    "\n",
    "# Specify the HTML file where you want to save the content\n",
    "html_output_file = 'output.html'\n",
    "\n",
    "# Save the HTML content to the HTML file\n",
    "with open(html_output_file, 'w', encoding='utf-8') as html_file:\n",
    "    html_file.write(html_content)\n",
    "\n",
    "# Print a message indicating where the HTML file is saved\n",
    "print(f'HTML content saved to {html_output_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502b2d7",
   "metadata": {},
   "source": [
    "# PDF to XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86aea73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Test.pdf', 'rb') as pdf_file:\n",
    "    # Create a BytesIO object to store the XML content\n",
    "    xml_output = BytesIO()\n",
    "\n",
    "    # Convert the PDF to XML and write it to the BytesIO object\n",
    "    extract_text_to_fp(pdf_file, xml_output, output_type='xml')\n",
    "\n",
    "    # Seek to the beginning of the BytesIO object\n",
    "    xml_output.seek(0)\n",
    "\n",
    "    # Read the XML content from the BytesIO object\n",
    "    xml_content = xml_output.read()\n",
    "\n",
    "# Save the XML content in a file\n",
    "with open('output.xml', 'wb') as output_file:\n",
    "    output_file.write(xml_content)\n",
    "\n",
    "# Close the BytesIO object\n",
    "xml_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17bbce5",
   "metadata": {},
   "source": [
    "# Customize Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f9ac652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bff72618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkforsection(text):\n",
    "    pattern = r\"^(?:(\\d|\\.)+\\s(?:[A-Z]+[a-z]*\\s?)+)|(?:[A-Z]+[a-z]*(\\s[A-Z][a-z]*)*)$\" #Extract Headings\n",
    "    match = re.fullmatch(pattern, text)\n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce55ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    clean_text = re.sub(r\"[\\n]\", \"\", text)\n",
    "    return (clean_text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d87c4",
   "metadata": {},
   "source": [
    "# Section Based Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ded35709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful Life Estimation Useful Life Estimation \n",
      "1. Introduction 1. Introduction \n",
      "2. Related Work 2. Related Work \n",
      "3. CNN LSTM Hybrid Deep Learning Architecture RUL Estimation 3. CNN LSTM Hybrid Deep Learning Architecture for RUL Estimation \n",
      "3.1. Convolutional Neural Network 3.1.  Convolutional Neural Network  \n",
      "3.2. LSTM Model 3.2.  LSTM Model \n",
      "3.4. Model Evaluation 3.4.  Model Evaluation \n",
      "4. Methodology 4. Methodology \n",
      "4.1. Data Preparation 4.1. Data Preparation \n",
      "4.2. Data Analysis 4.2. Data Analysis \n",
      "4.3.1. Data Filtering 4.3.1. Data Filtering \n",
      "4.3.2. Data Standardization 4.3.2. Data Standardization \n",
      "4.4.1. Principal Component Analysis 4.4.1. Principal Component Analysis \n",
      "4.4.3. Feature Selection 4.4.3. Feature Selection \n",
      "5. Experiments Results 5. Experiments and Results \n",
      "Hyperparameter Description List Values Best Estimator Hyperparameter Description List of Values Best Estimator \n",
      "7. Acknowledgements 7. Acknowledgements \n",
      "8. References 8. References \n"
     ]
    }
   ],
   "source": [
    "paragraphs = document_text.split(\". \\n\")\n",
    "ind = -1\n",
    "section_ind = []\n",
    "\n",
    "for p_ind in range(len(paragraphs)):\n",
    "    sentences = paragraphs[p_ind].split(\"\\n\")\n",
    "    sect_flag = False\n",
    "    for s_ind in range(len(sentences)):\n",
    "        words = sentences[s_ind].split(\" \")\n",
    "        section_sent = []\n",
    "        for word in words:\n",
    "            word = word.strip()\n",
    "            if word not in sw and word != \"\":\n",
    "                section_sent.append(word)\n",
    "        if checkforsection(\" \".join(section_sent)):\n",
    "            sect_flag = True\n",
    "            #print(\" \".join(section_sent), sentences[s_ind])\n",
    "            section_ind.append([p_ind, s_ind]) #[<Paragraph index>, <Section index>]\n",
    "            break\n",
    "    if not sect_flag:        \n",
    "        section_ind.append([p_ind, -1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e96ccc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "text_len = 10\n",
    "for index in section_ind:\n",
    "    if index[1] > -1:\n",
    "        paragraph = paragraphs[index[0]].split(\"\\n\")\n",
    "        if paragraph != \"\":\n",
    "            left_section = \" \".join(paragraph[:index[1]])\n",
    "            mid_section = paragraph[index[1]]\n",
    "            right_section = \" \".join(paragraph[index[1]+1 :])\n",
    "            if len(left_section) > text_len:\n",
    "                chunks.append(left_section.strip()) #left_section\n",
    "            if len(mid_section) > 1:\n",
    "                chunks.append((mid_section.strip())) #mid_section\n",
    "            if len(right_section) > text_len:\n",
    "                chunks.append(right_section.strip()) #right_section        \n",
    "    else:\n",
    "        clean_text = text_cleaning(paragraphs[index[0]])\n",
    "        if len(clean_text) > text_len:\n",
    "            chunks.append(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "743a0b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN-LSTM Hybrid Deep Learning Model for Remaining',\n",
       " 'Useful Life Estimation',\n",
       " '1Muthukumar G, 2Jyosna Philip  1 Technical Officer C, Indira Gandhi Centre for Atomic Research (IGCAR), Kalpakkam, Tamilnadu  Email: muthuganeshece@gmail.com / muthukumarg@igcar.gov.in  2 Student, M.Sc. (Data Science), Christ (deemed to be) University, Pune, India',\n",
       " 'Email: philipjyosna02@gmail.com',\n",
       " '1. Introduction',\n",
       " 'Remaining Useful Life (RUL) of a component or a system is defined as the length from the  current time to the end of the useful life [2]. Accurate RUL estimation plays a crucial role in  Predictive Maintenance applications. If we can accurately predict when an engine will fail, then we  can make informed maintenance decision in advance to avoid disasters, reduce the maintenance cost,  as well as streamline operational activities, aligning with the principles of industry 4.0 [1, 10]. In  general, two types of methodologies are used for RUL estimation: model-based approaches and data- driven approaches. Model-based methodologies build physical failure models for degradation, such as  crack, wear, corrosion, etc [1]. Physical models are very useful to solve RUL problem in use-cases  where there is no enough failure data available. In such cases, we can induce failures within physical  models, augment the actual data with physical model failure data and learn models for RUL  estimation. However, such physical failure models are very complex and difficult to build, and  physical models for many components do not exist. On the other hand, data-driven methods that  employ sensor and operational status data to estimate RUL are more advantageous and economical for  equipment with a sufficient number of failures.   In this paper, we conducted a thorough analysis of the data driven approach for RUL estimation',\n",
       " 'Traditional data driven approach utilizes both linear and non-linear regression techniques to estimate RUL, however they have difficulty achieving high accuracy in this field. Although Multilayer Perceptron (MLP) has been applied to predict RUL, it cannot learn salient features automatically, because of its network structure. However, it is extremely challenging, if not impossible, to accurately predict RUL without a good feature representation method. It is thus highly desirable to develop a systematic feature representation approach to effectively characterize the nature of signals related to the prognostic tasks.  Recently deep learning models are highly popular due to its ability to learn automatically the hierarchical feature representation from raw data. The deep learning architecture contains sequence of layers, each of which applies a non-linear transformation on the outputs of the previous layer. This allows the data to be represented by a hierarchy of features with varying levels of detail. The widely known deep learning models are Convolutional neural network (CNN), Recurrent Neural Network (RNN), Auto-encoders and Transformers.  Convolutional neural network  adapted from deep learning architecture uses different processing units such as convolution, pooling, activation etc., to effectively capture local features from the global data [27]. The deep architecture allows multiple layers of these units to be stacked, enabling the model to identify signal characteristics at different scales . Therefore, the features extracted by CNN are task dependent and non-handcrafted. Moreover, these features offer more predictive power, as the CNN is trained under the supervision of target values',\n",
       " 'Recurrent Neural Network, a class of deep learning architectures is well suited for modelling time sequence data [25]. However, RNN is known to suffer from long-term temporal dependency problem, as the gradients propagated over multiple stages tend to either vanish or explode. Long Short -Term Memory Network (LSTM) is a form of RNN network for sequence learning tasks  [5, 21] and has achieved remarkable success on speech recognition and machine translation. LSTM addresses the long-term time dependency problem of RNN by controlling information flow using input gate, forget gate and output gate. Long term memory retention is essentially their default mode of operation [23].  While Convolutional Neural Networks  have shown improved accuracy, th ey often overlook the sequential nature of the data, relying instead on features derived from sliding windows. Since RUL prediction inherently involves multivariate time series analysis, robust sequence learning is essential',\n",
       " 'Therefore, a novel hybrid architecture combining CNN with LSTM networks for RUL estimation is developed in this paper. Although CNN -based LSTM models have been applied to sequence prediction tasks in financial forecasting, this is the first attempt to adopt this approach for RUL estimation in prognostics.  In the proposed architecture for RUL estimation, one dimensional convolutional filters in the initial layer are applied to all the sensor data at each time stamp followed by LSTM layers applied temporally over the time series and the final neural network regression layer employs squared error loss function. In this approach, the CNN layer efficiently extracts features from the data, followed by LSTM  layer, which uses these extracted features to predict RUL. This method effectively leverages sensor sequence information, uncovering hidden patterns within the data, even under multiple operating conditions and fault scenarios',\n",
       " 'Data-driven approaches involve several key steps, including data collection, data wrangling, exploratory data analysis, feature engineering, and subsequent model preparation and evaluation. In the experiments, the proposed CNN with LSTM based approach for RUL estimation is compared with existing regression-based approaches in the CMAPSS public data set. The results clearly demonstrates that the proposed approach accurately predicts RUL than existing approaches significantly.  The following sections of this article are organized as follows:  Section 2 explains the background and related work.  Section 3  outlines the CNN LSTM hybrid Deep learning architecture . Section 4 describes the methodology, and  Section 5  discusses the experimental results.  Finally, Section 6 addresses the future work and conclusions',\n",
       " '2. Related Work',\n",
       " 'In t his section we primarily focus on regression-based machine learning approaches for RUL  estimation. There exist two main categories of ma chine learning -based techniques, t he first one is  supervised approaches where the failure information exists in the dataset and t he second one is  unsupervised approaches, where there is only process information, and no failure -related information  exists [30]. Supervised machine learning methods have been increasingly applied for RUL estimation  in the various areas such as medical devices [ 12], automated teller machines (ATM) [ 13], electric  propulsion systems [14, 29], rolling-element bearings [ 15], computer workstations [ 16], automobiles  [28] and industrial machines [29].   The existing algorithms in the literature for RU L estimation are either based on multivariate time  series analysis or damage progression analysis [3, 18, 19, 20, 26]. Many approaches utilize conventional  machine learning models such as support vector machines (SVM) [17] and decision tree-based models  [12, 13]. An important benefit of these models is their interpretability, as they help identify key factors  contributing to machine breakdowns',\n",
       " 'In [4], a deep convolutional neural network model is used to estimate RUL . In the proposed architecture, convolution filters in the initial layer are two dimensional which is  applied along the temporal dimension over the multi -channel sensor data and final neural network regression layer employs squared error loss function to incorporate automated feature learning from raw sensor signals in a systematic way.  Li et al. [ 32] developed a multi -scale deep convolutional neural network (MS -DCNN) and used the min-max normalization with the MS-DCNN algorithm for RUL prediction. They compared the performance of their model with other state -of-the-art models and showed that the new model provides promising results on the NASA C-MAPSS dataset [26]',\n",
       " 'In [ 5], LSTM network model is utilise d for the accurate  RUL estimation . Due to the inherent sequential nature of sensor data, LSTM is well suited for RUL estimation. In this approach, multiple layers of LSTM cells in combination with feed forward layers to uncover hidden patterns in sensor data at various stages of degradation',\n",
       " 'A set of turbo engine run-to-failure datasets is provided by NASA [26, 31], and the data is used in many research papers to predict the RUL. Ramasso and Saxena [24] published a survey on prognostic methods used for the NASA turbo engine datasets and divided the prognostic approaches  into three categories. The first category is the use of functional mappings between the set of inputs and RUL. For the first category, they reported that the dominant underlying machine learning algorithm is artificial neural networks (ANNs) [22]. The second category of techniques is the functional mapping between the health index and RUL. The third category is similarity -based matching techniques. Benchmarking of prognostic methods has been conducted on the NASA turbo engine dataset, and it was shown that  most of the studies use a health index to map between input features and the RUL',\n",
       " 'In several studies, indirect measurements of RUL are used in place of direct observations. Because of this, estimating the RUL frequently involves the use of the health inde x (HI) concept [34]. Rather than directly predicting the RUL, a machine learning model is trained to forecast the HI of a turbo engine for each cycle . Ziqiu et al. [33] used the notion of  HI and the Multilayer Perceptron (MLP) machine learning method in combination with feature normalization, Principal Component Analysis (PCA), and feature selection approaches  to estimate the RUL . They also used the NASA CMAPSS dataset to assess the performance of their model',\n",
       " 'In our study, we adopt to the supervised machine learning approach for the estimation of RUL using a deep CNN combined with LSTM architecture. In consistent with other models, we thoroughly investigate the effectiveness of this innovative model and compare its performance against other established machine learning algorithms using the NASA turbo engine datasets',\n",
       " '3. CNN LSTM Hybrid Deep Learning Architecture for RUL Estimation',\n",
       " 'This section presents the proposed architecture of CNN LSTM hybrid deep learning model for RUL  estimation. CNN have great potential to identify the various salient patterns of sensor signals. However,  in RUL estimation we confront with multiple  channels of time series signals, in which the traditional  CNN cannot be used directly. Hence, we hybrid the LSTM network to capture temporal dimension. The  LSTM module receives the output from the CNN module and processes it sequentially to capture long- term dependencies and temporal patterns . It uses multiple layers of LSTM cells in combination with  standard feed forward layers to discover hidden patterns from sensor data. The overview block diagram  of the CNN LSTM architecture is shown in the Fig. 1',\n",
       " 'Fig. 1: Block Diagram of proposed CNN LSTM hybrid architecture',\n",
       " '3.1.  Convolutional Neural Network',\n",
       " 'In our work, we have limited the architecture to a single CNN layer, which consists of one  convolution layer followed by a pooling layer. This simplified structure is sufficient for this task, which  helps to reduce computational complexity. In the convolution layer, the input sensor data at a specific  time instant is processed using one -dimensional convolutional kernels. We apply 64 one dimensional  convolution filters  and relu activation function . In the pooling layer, we use one dimensional max  pooling without overlapping, where the input feature maps are divided into non -overlapping regions,  and for each sub-region, the maximum value is taken as the output',\n",
       " '3.2.  LSTM Model',\n",
       " 'LSTM cell uses memory cells and three gates as shown in Fig. 2.     Fig. 2: LSTM Cell  The forget gate determines what information to discard, the input gate controls new information  added, and the output gate manages how much of the cell state is used for output  as shown in Fig. 2 .   Sensor  Inputs  CNN  Layer  Pooling  Layer  LSTM  Layer  Dense  Layer  RUL  Output  This structure allows LSTMs to effectively retain important informati on over time, making them  suitable for tasks like time -series prediction and sequence modeling.  Hence, we split the dataset into  multiple fixed length time series data of length 30 and applied to the model.   3.3.  CNN LSTM Architecture  The CNN module processes the input data and extracts relevant spatial features through  convolutional layers. These layers employ filters to capture local patterns within the input sequences,  enabling the model to learn hierarchical representations of the data. The LSTM module rece ives the  output from the CNN module and processes it sequentially to capture long -term dependencies and  temporal patterns. In the proposed CNN LSTM hybrid architecture shown in Fig. 3, leverages the  strengths of both CNNs and LSTMs to capture spatial patterns and long-term dependencies in sequential  data. We combined the 1D convolution layer followed by pooling layer with multiple LSTM and fully  connected layers. CNN takes the input sensor data at each time step and its output is passed to LSTM  layer. The LSTM output is then fed into fully connected layers, and the final regression layer predicts  the RUL',\n",
       " 'Fig. 3: CNN LSTM Hybrid Architecture Model',\n",
       " '3.4.  Model Evaluation',\n",
       " 'In order to evaluate the performance of a RUL estimation model on the test data, Root Mean  Square Error (RMSE) Eq. (1), gives equal penalty weights to the model when the estimated RUL is  smaller than true RUL and when the estimated RUL is larger than true RUL.                   (1)    Eq. (2) is R² Score, which is also widely used as an evaluation metric for the estimation of RUL. It  represents the proportion of variance in the target variable that can be explained by the independent  variables in the model. Mathematically, the R² score is defined as:               (2)     Where SSres is the sum of squared residuals (the differences between the observed and predicted  values), and SStot is the total sum of squares (the differences between the observed values and their  mean). R² score of 1 indicates that the model perfectly explains all the variability in the target variable  and an R² score of 0 suggests that the model fails to explain any variability and performs no better  than a simple mean-based prediction',\n",
       " 'In literature, scoring function is given to measure the quality of the models [4, 5]. Eq. (3) shows the definition of scoring function',\n",
       " '(3) Where n is total number of samples in the test set, hi = RULest,i - RULi, RULi is true RUL for the test sample ‘i’. Eq. (3) gives different penalty when the model underestimates RUL and when the model overestimates RUL. If estimated RUL is less than the true RUL, the penalty is smaller, because there is still time to conduct maintenance and it will not cause significant system failure. If estimated RUL is larger than true RUL, the penalty is larger, because under such estimation, the maintenance will be scheduled later than the required time and it may cause system failure',\n",
       " '4. Methodology',\n",
       " 'This section outlines the key steps taken before the modeling phase. It starts with preparing features  and target variables, followed by data analysis to explore relationships between variables using  visualizations. Data pre -processing is then discussed, including filtering and normalization. Feature  engineering is applied to create or modify features for better predictive power. Finally, techniques like  Principal Component Analysis (PCA) and feature selection are used to remove redundant or irrelevant  features',\n",
       " '4.1. Data Preparation',\n",
       " 'The dataset comprises multiple multivariate time series sensor data, which is divided into training  and test subsets. Each time series is from a different engine i.e., the data can be considered to be from  a fleet of engines of the same type. Every engine has varying degrees of initial wear and manufacturing  variance in the beginnin g. This variation and wear are regarded as normal and do not indicate a  malfunction. The data is contaminated with sensor noise. The engine is operating normally at the start  of each time series, and develops a fault at some point during the series. In the  training set, the fault  grows in magnitude until system failure. In the test set, the time series ends some time prior to syste m  failure. The objective is to predict the number of remaining operational cycles before failure in the test  set, or in other words the number of cycles the engine will continue to operate after the last recorded  cycle. In addition to that a vector of true RUL for the test set is also provided in the dataset',\n",
       " 'The dataset contains 26 numerical features, where each row represents a snapshot of data collected in a single operational cycle across 100 different engines. Sensor data is recorded during each engine power cycle and is gathered for one hundred distinct engines. Engine ID, Time in Cycles, Settings 1, 2, 3, and the remaining columns all contain sensor data. There is no formal definition of the specifics of any sensor data',\n",
       " 'Fig. 4: Piece-wise RUL of the Data Set (Piece-wise maximum RUL is 130-time cycles) The target variable is not exp licitly provided in the dataset,  instead it is calculated by subtracting the number of cycles from the engine’s maximum cycle. This leads to a new column labelled \"Remaining Cycles,\" which becomes the target variable and it represents the Remaining Useful Life of the engine. The health of a system generally degrades linearly along with time. In practical applications, a component\\'s degradation is minimal at first and grows as it gets closer to its end of life. A piece-wise linear RUL target function was proposed in [3, 4] , in order to better reflect the changes in Remaining Useful Life over time. This function sets a maximum RUL and then begins linear degradation at a specific usage level as shown in the Fig. 4. We set the maximum limit as 130 time cycles for all the engines',\n",
       " '4.2. Data Analysis',\n",
       " 'The Fig. 5 shows the sensor readings for one of the engines over the course of its lifetime. The  sensor values are displayed on the Y-axis, while the power cycles are represented on the X-axis. From  the graph, it can be observed that sensors such as Sensor 3, Sensor 4, Sensor 8, Sensor 9, Sensor 13,  Sensor 19, Sensor 21, and Sensor 22 maintain constant readings throughout their lifecycle. Since these  constant sensor readings do not contribute any predictive value, these features can be safely removed  from the dataset',\n",
       " 'Fig 5: Time series sensor data of one of the Engines The distribution of each sensor data in the dataset varies significantly. As per Fig. 6, some sensors, such as 1, 5, and 6, exhibit a normal distribution  and the remaining sensors display skewed distributions, either to the right or left. This diverse range of data distributions necessitates tailored pre-processing techniques to ensure optimal model performance',\n",
       " 'Fig. 6: Frequency Distribution Plot for Sensor Data  Fig. 7: Parallel Coordinates plot for CMAPSS Dataset Parallel Plot [11] is a type of data visualization used to explore and analyse multi-dimensional data. Parallel pl ot applied to the dataset  is displayed in Fig. 7,  where dark blue lines represent observations with more remaining cycles, while yellow lines indicate lower remaining cycles.  The sensor values tend to be more consistent and grouped together in the early cycles, which are represented by dark blue lines and suggest stable operation. Sensor readings begin to differ as the engines get closer to the middle of their lives; this is a sign of both performance discrepancies and the onset of defects',\n",
       " \"The sensor values exhibit a substantial divergence, suggesting wear and degradation, as the sensor  approaches its end of life, indicated by yellow lines.   The sensor data for all engines is illustrated in the Fig. 8. The green dots in this graphic show  the exponential moving average of the sensor data for one engine throughout the course of its lifetime,  while the red points show the points at which each engine fails. With the exception of Sensors 1 and 2,  it is clear from the figure that the majority of sensors are able to differentiate between the engine's   normal operating circumstances and failure scenarios. As a result, the characteristics associated with  Sensors 1 and 2 can be disregarded for additional examination. Furthermore, some sensor readings are  positive correlation with degradation and while others show a negatively correlation.       Fig. 8: Scatter plot representation of sensor data of all engines  4.3.  Data Pre-processing  Data preprocessing is essential before modeling as it enhances data quality, ensuring that the  input data is accurate, consistent, and relevant.  The techniques such as cleaning and standardization  rectify errors and inconsistencies, leading to more reliable models.\",\n",
       " '4.3.1. Data Filtering',\n",
       " 'The sensor data in the dataset are noisy and sporadic, necessitating the application of  smoothing filters to improve data quality. Two widely used smoothing techniques such as Simple  Moving Average (SMA) and Exponential Moving Average (EMA), were applied with various  weights to determine the most effective method. Upon evaluation, EMA with an alpha value of 0.1  visually outperformed other configurations. Consequently, EMA with this alpha value was selected  and applied to the sensor data, resulting in a smoother and more reliable data. Fig. 9 shows a visual  comparison of raw sensor data and the exponential mean of sensor data with alpha = 0.1. In the raw  data, the data points are far more scattered than their corresponding exponential mean. Therefore, the  modified data may provide better results for the model than using the raw sensor data directly',\n",
       " 'Fig. 9: Comparison between Raw sensor data and exponential moving averaged sensor data',\n",
       " '4.3.2. Data Standardization',\n",
       " 'Since the value range is substantially different in different variables, it can be difficult to find  the optimal point for the cost function. Therefore, the training and testing datasets need to be  normalized. There are two widely used methods for normaliz ation, which are Z-scores as specified in  Eq. (4) and min-max-scale as specified in Eq. (5). Both methods are applied, and the one with the best  evaluation result is selected.           (4)               (5)    4.4.  Feature Engineering  In the dataset, some features exhibit constant values throughout all observations, resulting in  zero variance. These features are removed in the previously discussed data analysis section, as they  provide no meaningful insight into the relationship between the input variables and the target variable',\n",
       " \"In addition to that, feature transformation can be applied to further optimize the dataset. By removing or transforming such features, the model's performance can be significantly improved\",\n",
       " '4.4.1. Principal Component Analysis',\n",
       " 'As part of feature engineering, Principal Component Analysis (PCA) was applied to reduce the  dimensionality of the high -dimensional sensor data. PCA projects the data onto orthogonal axes,  retaining the most significant features. The cum ulative explained variance ratio, shown in Fig. 10,  indicates that the first two components capture around 70% of the variance, while 12 components  account for nearly 99%. Therefore, the data dimension can be reduced from 24 to 12 with minimal loss  of information',\n",
       " \"Fig. 10: Explained Variance Ratio of Principal Components The first, second, and third principal components are studied extensively as they represent 75% of the dataset's variance. Fig. 11 represents the scatter plot for the complete dataset, wh ere green dots represent the starting points of the engine cycles, and orange dots represent the failure points. It becomes evident from the scatter plot that thresholding the first principal component can effectively determine the failure point of all engines, irrespective of the other principal components\",\n",
       " 'Fig. 11: Correlation plot of first 3 principal components 4.4.2. Multi collinearity Analysis When working with multiple numerical features in a dataset, it is essential to analyse the correlation between these features. Highly correlated features can introduce redundancy, biasing the model and ultimately reducing the accuracy of predictions. When two or more features provide similar information, the model may overemphasize their contributions, leading to overfitting or skewed results',\n",
       " \"From the heat map shown in Fig. 12, it is evident that lot of features are highly correlated and it can lead to multi collinearity problem. Multicollinearity refers to the situation where two or more f eatures in a dataset are highly correlated, which can negatively impact the performance of machine learning models. Therefore, it is crucial to select features that contribute the most to the model's performance while minimizing redundancy\",\n",
       " 'Fig. 12: Heat map of the features in CMAPSS dataset',\n",
       " '4.4.3. Feature Selection',\n",
       " \"From the Fig. 13, it is evident that the first principal component can be segregated to indicate  failure, which helps the model in tuning the remaining useful life (RUL). Therefore, the first principal  component is included as an additional feature for model development. This inclusion enhances the  model's ability to predict RUL more accurately by leveraging the significant variance captured by the  first principal component\",\n",
       " 'Fig. 13: Principal Components Vs Cycles To tackle the issue of multicollinearity , as discussed in the previous section , we applied the Select K Best algorithm. This algorithm ranks all the features according to a specified statistical criterion and selects the top K features that are most significant for predicting the target variable. Fig',\n",
       " '14 clearly shows that the logarithmic F-scores of Sensor1 and Sensor2 are significantly low, indicating their minimal importance. Therefore, these sensors can be removed due to their limited contribution',\n",
       " 'Fig. 14: Features ranked based on F-scores by Select K Best Algorithm',\n",
       " '5. Experiments and Results',\n",
       " 'In this section, we have performed extensive experiments for comparison of the proposed CNN  LSTM based deep learning model with traditional regression algorithms such as Linear Regression,  Random Forest  [6], and state -of-the-art algorithms, including Multi -layer Perceptron (MLP)  [9],  XGBoost [7, 8] and LSTM on the CMAPSS data set. The hyper  parameters of all the techniques, are  chosen using standard 5 -fold cross -validation procedure, where we tune their parameter values for  training these models and choose their final values that give the best results',\n",
       " 'The hyperparameter tuning for the Random Forest, XG boost, MLP are performed as shown in the  Table 1 and Table 2.   Table 1: Hyperparameter Tuning for Random Forest',\n",
       " 'Hyperparameter Description List of Values Best Estimator',\n",
       " 'n_estimators No. of Trees [100,200,300] 300  max_depth Maximum depth of trees [6,8,10,12,14] 6  min_samples_leaf Minimum of samples for leaf [4,6,8,10] 4  ccp_alpha Tree pruning factor [0,1,2] 0  Table 2: Hyperparameter Tuning for XG Boost  Hyperparameter Description List of Values Best Estimator  learning_rate Learning Rate [0.05,0.1,0.2] 0.1  n_estimators No. of Trees [70,100,200,300] 70  max_depth Maximum depth of trees [3,4,5] 3  min_child_weight Minimum sum of instance weights [70,100,150,200] 200  Table 3: Hyperparameter Tuning for MLP  Hyperparameter Description List of Values Best Estimator  learning_rate Learning Rate [0.05,0.1,0.2] 0.1  n_layers No. of layers [3,4,5,6] 5  layer_sizes No. of neuron in layers  [8.16.64.32.8,  16.32.64.32.16,  32.64.64.32.16]  32.64.64.32.16   The performance of the previously discussed machine learning algorithms are compared with the  performance of the proposed model and the results are shown in Table 4. From the table, it is evident  that the proposed hybrid CNN-LSTM model demonstrates the better RMSE and offering a superior R²  score compared to the other methods',\n",
       " \"Table 4: Performance comparison on C-MAPSS dataset  Model RMSE R2  Linear Regression 43.18 0.46  Random Forest 6.68 0.42  XG Boost 17.35 0.65  MLP 4.51 0.52  LSTM 15.93 0.75  CNN LSTM 13.34 0.86    6. Conclusion and Future work  We proposed CNN LSTM based deep learning approach for RUL estimation and we showed its  benefits by taking sequence information when estimating RUL. Our experiments on C-MAPSS dataset  showed that our proposed model outperforms other approaches and gives the best performance in RUL  estimation. In addition to that, the work involves the entire lifecycle of predictive maintenance, starting  with data collection, followed by comprehensive data preparation and pre -processing stages to ensure  data quality and consistency. Feature scaling, Pr incipal Component Analysis (PCA), and feature  selection techniques were applied to refine the dataset and identify the most relevant features for  modeling. Multiple algorithms, including Linear Regression, Random Forest, XG-Boost, MLP, and  LSTM, were developed and evaluated using RMSE and R² metrics. Future work will focus on extending  this experiment to other RUL estimation datasets to validate the robustness of the proposed model across  different scenarios. A notable challenge with the proposed model is its computational complexity,  which impacts its suitability for deployment in embedded devices. To address this, optimization  strategies will be explored to increase the model's computation speed, making it more efficient and  feasible for real-time applications on low-power embedded systems.\",\n",
       " '7. Acknowledgements',\n",
       " 'The authors would like to express their gratitude and appreciation to their team members,  Abhay  Sharma, Anchal Sekhri, Sana Zehra and Khunwana Zeno, for their invaluable inputs and support during  the course of a project related to this research work',\n",
       " '8. References',\n",
       " '[1] S. Duffuaa, M. Ben-Daya, K. Al-Sultan, and A. Andijani: “A generic conceptual simulation model  for maintenance systems,” Journal of Quality in Maintenance Engineering, vol. 7, pp. 207–219, 2001',\n",
       " '[2] X.-S. Si, W. Wang, C.-H. Hu, and D.-H. Zhou: “Remaining useful life estimation–a review on the statistical data driven approaches,” European Journal of Operational Research, vol. 213, pp. 1–14, 2011 [3] Heimes, F.O.: “Recurrent neural networks for remaining useful life estimation ”, in International Conference on Prognostics and Health Management, 2008.  [4] G. S. Babu, P. Zhao, and X.-L. Li: “Deep convolutional neural network based regression approach for estimation of remaining useful life,” in International Conference on Database Systems for Advanced Applications. Springer, 2016, pp. 214–228 [5] Shuai Zheng, Kosta Ristovski, Ahmed Farahat and Chetan Gupta : “Long Short -Term Memory Network for Remaining Useful Life Estimation,” in IEEE ICPHM, 2017 [6] Breiman. L: “Random Forests”, Machine Learning, 45(1), 5-32, 2001 [7] Chen. T & Guestrin. C: “XGBoost: A Scalable Tree Boosting System”, in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016',\n",
       " '[8] Xgboost Developers: “XGBoost Documentation”, Available: https://xgboost.readthedocs.io [9] Scikit-learn Developers: “Scikit-learn Documentation: MLPRegressor”, Available: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html [10] S. Abirami and P. Chitra : “The Digital Twin Paradigm for Smarter Systems and Environments: The Industry Use Cases,” in Advances in Computers, 2020',\n",
       " '[11] Wegman, E. J. : “Hyperdimensional Data Analysis Using Parallel Coordinates, ” Journal of the American Statistical Association, vol. 85, 1990 [12] Ruben Sipos, Dmitriy Fradkin, Fabian Moerchen, and Zhuang Wang : “Log based predictive maintenance”, in Proceedings of the 20th ACM SIGKDD international conference on knowledge discovery and data mining. 1867–1876',\n",
       " '[13] Antoine Guillaume, Christel Vrain, and Elloumi Wael : “Time series classification for predictive maintenance on event logs”, arXiv: 2011.10996, 2020',\n",
       " '[14] Deokwoo Jung, Zhenjie Zhang, and Marianne Winslett : “Vibration analysi s for IOT enabled predictive maintenance”, in IEEE 33rd International Conference on Data Engineering (ICDE), 2017.  [15] Dovile Juodelyte, Veronika Cheplygina, Therese Graversen, and Philippe Bonnet : “Predicting Bearings Degradation Stages for Predictive Maintenance in the Pharmaceutical Industry”, 2022',\n",
       " '[16] Alexander Nikitin and Samuel Kaski:  “Human-in-the-Loop Large-Scale Predictive Maintenance of Workstations”, in Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2022',\n",
       " '[17] Corinna Cortes and Vladimir Vapnik: “Support-vector networks”, Machine learning, 1995',\n",
       " '[18] Wang, T., Yu, J., Siegel, D., Lee, J.: “A similarity-based prognostics approach for remaining useful life estimation of engineered systems”, in International Conference on Prognostics and Health Management, 2008',\n",
       " '[19] Lim, P., Goh, C.K., Tan, K.C., Dutta, P.: “Estimation of remaining useful life based on switching kalman filter neural network ensemble”, in Annual Conference of the prognostics and Health Management Society, 2014, pp. 1–8 [20] Ramasso, E., Saxena, A.: “Review and analysis of algorithmic approaches developed for prognostics on CMAPSS dataset”, in Annual Conference of the Prognostics and Health Management Society, 2014, pp. 1–11 [21] F. A. Gers, D. Eck, and J. Schmidhuber: “Applying LSTM to time series predictable through time-window approaches,” pp. 669–676, 2001',\n",
       " '[22] Z. Tian: “An artificial neural network method for remaining useful life prediction of equipment subject to condition monitoring,” Journal of Intelligent Manufacturing, vol. 23, pp. 227–237, 2012',\n",
       " '[23] S. Hochreiter and J. Schmidhuber: “Long short-term memory,” Neural computation, vol. 9, no. 8, pp. 1735–1780, 1997',\n",
       " '[24] E. Ramasso and A. Saxena: “Performance benchmarking and analysis of prognostic methods for cmapss datasets.” International Journal of Prognostics and Health Management, vol. 5, pp. 1–15, 2014 [25] Connor, J.T., Martin, R.D., Atlas, L.E.: “Recurrent neural networks and robust time series prediction”, IEEE Transactions on Neural Networks 5(2), 240–254, 1994 [26] Saxena, A., Goebel, K., Simon, D., Eklund, N: “Damage propagation modeling for aircraft engine run-to-failure simulation”, in International Conference on Prognostics and Health Management, 2008. PHM 2008. pp. 1–9 [27] Yang, J.B., Nguyen, M.N., San, P.P., Li, X.L., Krishnaswamy, S: “Deep convolutional neural networks on multichannel time series for human activity recognition”, in Proceedings of the 24th International Conference on Artificial Intelligence. pp. 3995–4001. AAAI Press (2015) [28] Abdul Basit Hafeez, Eduardo Alonso, Aram Ter-Sarkisov: “Towards Sequential Multivariate Fault Prediction for Vehicular Predictive Maintenance”, in 20th IEEE International Conference on Machine Learning and Applications (ICMLA), 2021 [29] Hadi Ashraf Raja, Karolina Kudelina, Bilal Asad and Toomas Vaimann: “Fault Detection and Predictive Maintenance of Electrical Machines”, IntechOpen: London, UK, 2022 [30] Susto G.A., Schirru A., Pampuri S., McLoone S., Beghi A.: “Machine learning for predictive maintenance: A multiple classifier approach”, in IEEE Trans. Ind. Inform., 2014 [31] Saxena A., Goebel K.: “Turbofan Engine Degradation Simulation Data Set”, 2008 [32] Li H., Zhao W., Zhang Y., Zio E.: “Remaining useful life prediction using multi-scale deep convolutional neural network”, Appl. Soft Computing, 2020 [33] Ziqiu Kang, Cagatay Catal, and Bedir Tekinerdogan: “Remaining Useful Life (RUL) Prediction of Equipment in Production Lines Using Artificial Neural Networks”, PubMed Central, 2021 [34] Riad A., Elminir H., Elattar H.: “Evaluation of neural networks in the subject of prognostics as compared to linear regression model”, in International Journal of Engineering and Technology, 2010']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5b4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
